{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate import AlignedSent, Alignment\n",
    "import goslate\n",
    "import time\n",
    "from translate import Translator\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading mag file:  ../data/mag/Digital Scholarship in the Humanities (DSH).csv\n",
      "Reading mag file:  ../data/mag/International Journal of Digital Humanities.csv\n",
      "Reading mag file:  ../data/mag/Digital Studies - Le champ numérique.csv\n",
      "Reading mag file:  ../data/mag/International Journal of Humanities and Arts Computing.csv\n",
      "Reading mag file:  ../data/mag/Digitális Bölcsészet - Digital Humanities.csv\n",
      "Reading mag file:  ../data/mag/Frontiers in Digital Humanities.csv\n",
      "Reading mag file:  ../data/mag/AI _ SOCIETY part 2.csv\n",
      "Reading mag file:  ../data/mag/Journal of Library Metadata.csv\n",
      "Reading mag file:  ../data/mag/Journal of Quantitative Linguistics.csv\n",
      "Reading mag file:  ../data/mag/AI _ SOCIETY.csv\n",
      "Reading mag file:  ../data/mag/Computers and the Humanities part 2.csv\n",
      "Reading mag file:  ../data/mag/Journal of Cultural Analytics.csv\n",
      "Reading mag file:  ../data/mag/Computers and the Humanities.csv\n",
      "Reading mag file:  ../data/mag/International Journal on Digital Libraries.csv\n",
      "Reading mag file:  ../data/mag/D-Lib Magazine part 2.csv\n",
      "Reading mag file:  ../data/mag/D-Lib Magazine.csv\n",
      "Reading mag file:  ../data/mag/Computational Linguistics.csv\n",
      "Reading mag file:  ../data/mag/Virtual Archaeology Review.csv\n",
      "Reading mag file:  ../data/mag/Journal of the Japanese Association for Digital Humanities.csv\n",
      "Reading mag file:  ../data/mag/Literary and Linguistics Computing part 2.csv\n",
      "Reading mag file:  ../data/mag/Language Resources and Evaluation.csv\n",
      "Reading mag file:  ../data/mag/Journal of the Text Encoding Initiative.csv\n",
      "Reading mag file:  ../data/mag/Digital Medievalist.csv\n",
      "Reading mag file:  ../data/mag/Revista de humanidades digitales.csv\n",
      "Reading mag file:  ../data/mag/Literary and Linguistics Computing.csv\n",
      "Reading mag file:  ../data/mag/Journal on Computing and Cultural Heritage (JOCCH).csv\n",
      "Reading mag file:  ../data/mag/INTERNATIONAL JOURNAL OF DIGITAL CURATION.csv\n"
     ]
    }
   ],
   "source": [
    "# Read all the MAG csv datasets\n",
    "DIR_ROOT = \"../data/mag/\"\n",
    "MAG_DICT = {}\n",
    "\n",
    "for r, d, f in os.walk(DIR_ROOT):\n",
    "    for file in f:\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(r, file)\n",
    "            print(\"Reading mag file: \",file_path)\n",
    "            with open(file_path, 'r') as csv_file:\n",
    "                MAG_DICT[file] = pd.DataFrame(csv.reader(csv_file))         \n",
    "                #Convert the first line into columns\n",
    "                MAG_DICT[file].columns = MAG_DICT[file].iloc[0]\n",
    "                MAG_DICT[file] = MAG_DICT[file].reindex(MAG_DICT[file].index.drop(0)).reset_index(drop=True)\n",
    "                MAG_DICT[file].columns.name = None\n",
    "                \n",
    "                #Normalize the dataframe\n",
    "                def aff_val_filter(x):\n",
    "                    return x.strip() != \"\"\n",
    "                \n",
    "                MAG_DICT[file][\"AA.DAfN\"] = MAG_DICT[file][\"AA.DAfN\"].apply(lambda x: list(filter(aff_val_filter, x.split(\";;\")))) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST the results\n",
    "# COMMENT this PArt\n",
    "#MAG_DICT[\"International Journal of Humanities and Arts Computing.csv\"]\n",
    "#MAG_DICT[\"Literary and Linguistics Computing part 2.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACDH_INST_PATH = \"../data/acdh/institutions.json\"\n",
    "with open(ACDH_INST_PATH) as json_file:\n",
    "    acdh_inst = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the unique institutions we have \n",
    "# Some values should ba manually corrected \n",
    "# For instance: 'Consiglio Nazionale delle Ricerche'  _and_ 'Consiglio Nazionale delle Ricerche - CNR' are the same institution\n",
    "# This goes out of this work\n",
    "\n",
    "inst_df = pd.DataFrame(acdh_inst)\n",
    "inst_df = inst_df[[\"name\",\"id\"]]\n",
    "inst_df.columns = ['acdh_name','id']\n",
    "inst_df['acdh_name'] = inst_df['acdh_name'].apply(lambda x: x.strip().lower()) \n",
    "#inst_df['language'] = inst_df['acdh_name'].apply(lambda x: gs.detect(x))\n",
    "inst_df['acdh_name_eng'] = inst_df['acdh_name'].apply(lambda x: Translator(from_lang = \"autodetect\", to_lang=\"en\").translate(x).lower())\n",
    "inst_df['acdh_name_eng'] = inst_df['acdh_name_eng'].apply(lambda x: '' if 'please select' in x else x)\n",
    "#inst_df['acdh_tokenized'] = inst_df['acdh_name'].apply(lambda x: list(set(word_tokenize(x)) - set(stopwords.words('english'))) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we check how many elements are similar to what we have in MAG\n",
    "ROOT_PATH = '../data/mag_acdh_join/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join International Journal of Humanities and Arts Computing.csvwith acdh institutions ...\n",
      "Join Digitális Bölcsészet - Digital Humanities.csvwith acdh institutions ...\n",
      "Join Frontiers in Digital Humanities.csvwith acdh institutions ...\n",
      "Join AI _ SOCIETY part 2.csvwith acdh institutions ...\n",
      "Join Journal of Library Metadata.csvwith acdh institutions ...\n",
      "Join Journal of Quantitative Linguistics.csvwith acdh institutions ...\n",
      "Join AI _ SOCIETY.csvwith acdh institutions ...\n",
      "Join Computers and the Humanities part 2.csvwith acdh institutions ...\n",
      "Join Journal of Cultural Analytics.csvwith acdh institutions ...\n",
      "Join Computers and the Humanities.csvwith acdh institutions ...\n",
      "Join International Journal on Digital Libraries.csvwith acdh institutions ...\n",
      "Join D-Lib Magazine part 2.csvwith acdh institutions ...\n",
      "Join D-Lib Magazine.csvwith acdh institutions ...\n",
      "Join Computational Linguistics.csvwith acdh institutions ...\n",
      "Join Virtual Archaeology Review.csvwith acdh institutions ...\n",
      "Join Journal of the Japanese Association for Digital Humanities.csvwith acdh institutions ...\n",
      "Join Literary and Linguistics Computing part 2.csvwith acdh institutions ...\n",
      "Join Language Resources and Evaluation.csvwith acdh institutions ...\n",
      "Join Journal of the Text Encoding Initiative.csvwith acdh institutions ...\n",
      "Join Digital Medievalist.csvwith acdh institutions ...\n",
      "Join Revista de humanidades digitales.csvwith acdh institutions ...\n",
      "Join Literary and Linguistics Computing.csvwith acdh institutions ...\n",
      "Join Journal on Computing and Cultural Heritage (JOCCH).csvwith acdh institutions ...\n",
      "Join INTERNATIONAL JOURNAL OF DIGITAL CURATION.csvwith acdh institutions ...\n"
     ]
    }
   ],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "for k in MAG_DICT:\n",
    "    #if already processed move on the next one\n",
    "    if os.path.exists('../data/mag_acdh_join/'+k.replace(\".csv\",\"\")+'.json'):\n",
    "        continue\n",
    "    print(\"Join \"+k+\"with acdh institutions ...\")\n",
    "    new_column = []\n",
    "    for index, row in MAG_DICT[k].iterrows():\n",
    "        \n",
    "        l_aff = []\n",
    "        for aff in row['AA.DAfN']:    \n",
    "            # Check inside the ACDH affiliations if present\n",
    "            flag_found = -1\n",
    "            for index_acdh, row_acdh in inst_df.iterrows():\n",
    "                if ((similar(row_acdh[\"acdh_name\"],aff) > 0.8) or (similar(row_acdh[\"acdh_name_eng\"],aff) > 0.8)):\n",
    "                    flag_found = row_acdh[\"id\"]\n",
    "                    break\n",
    "            \n",
    "            l_aff.append(flag_found)\n",
    " \n",
    "        new_column.append(l_aff)\n",
    "\n",
    "    # add the new column\n",
    "    MAG_DICT[k][\"acdh_aff\"] = new_column\n",
    "    \n",
    "    MAG_DICT[k][[\"AA.DAfN\",\"DOI\",\"acdh_aff\"]].to_json(r'../data/mag_acdh_join/'+k.replace(\".csv\",\"\")+'.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/res/affiliation.json\") as json_file:\n",
    "    affiliation_df = pd.DataFrame(json.load(json_file))\n",
    "\n",
    "ERRORS = [\" Pisa\"]\n",
    "affiliation_df = affiliation_df.set_index('DOI').drop(\" Pisa\")\n",
    "affiliation_df.to_json(\"../data/res/affiliation(with_id).json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DRAFT\n",
    "\n",
    "#all_data = []\n",
    "#for r, d, f in os.walk(ROOT_PATH):\n",
    "#    for file in f:\n",
    "#        if file.endswith(\".json\"):\n",
    "#            file_path = os.path.join(ROOT_PATH, file)\n",
    "#            with open(file_path) as json_file:\n",
    "#                all_data = all_data + json.load(json_file)\n",
    "\n",
    "#with open(ROOT_PATH+'affiliation.json', 'w') as file:\n",
    "#     file.write(json.dumps(all_data)) # use `json.loads` to do the reverse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
